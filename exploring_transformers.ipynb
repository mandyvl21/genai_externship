{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2897",
   "metadata": {},
   "source": [
    "# Transformer Text Generation\n",
    "\n",
    "In this notebook, we will explore how transformer models (like GPT-2) can generate text based on a given prompt. We will experiment with generating text by adjusting parameters like temperature and sequence length.\n",
    "\n",
    "## Instructions\n",
    "1. Change the prompt below to experiment with different types of text generation.\n",
    "2. Adjust the `max_length` and `temperature` parameters to see how they affect the output.\n",
    "3. Generate at least 3 samples with different prompts and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Output 1 ===\n",
      "\"I'm in love with you,\" she said. He turned his head to look at her. \"We're both lucky. You've seen it before. All of these other people have, like, the same thing.\"\n",
      "\n",
      "\"I think I'm lucky; I grew up with a boyfriend, too,\" he said quickly. \"Not an alcoholic.\"\n",
      "\n",
      "\"I saw an 8-year-old at school,\" she said, making fun of him.\n",
      "\n",
      "\"I saw a movie, too,\" he said sadly, taking one last look at her. \"It's like your favorite movie is the one you were watching, too. We had been drinking all along, and when you're in high school, you're as nervous as I am. This, I mean, I don't know why. I can't believe it.\"\n",
      "\n",
      "It was another week for the rest of his life. All the pictures he took of her that day were gone. He'd grown tired of her. He'd never seen her in person. Even if he did see her, she'd vanished. He would often leave his job, his home, his parents' house, everything behind him. The only thing left was another jobâ€¦\n",
      "\n",
      "That was a week ago.\n",
      "\n",
      "\"I thought you were going to be\n",
      "\n",
      "=== Output 2 ===\n",
      "\"I'm in love with you,\" she said.\n",
      "\n",
      "\"Yes!\"\n",
      "\n",
      "She picked up a pair of scissors.\n",
      "\n",
      "\"Can you read my tongue?\" she asked. \"I can be read by anything because I had this mouth filled with saliva,\" she said. \"I can be read by anything because it's always been there. Can I feel you're hurting me?\"\n",
      "\n",
      "She took the scissors off her finger. \"We don't do this to be seen. We do it because it's a love thing,\" she said.\n",
      "\n",
      "A few moments after that, the waitress offered the pair of scissors to the two strangers who had arrived from the door.\n",
      "\n",
      "\"I'm sorry, you're late,\" said the waitress. \"I'm sorry. I was wrong about your phone. You should have called.\"\n",
      "\n",
      "\"Just call this girl as soon as possible.\"\n",
      "\n",
      "She then went back to her kitchen and handed the two hands around.\n",
      "\n",
      "\"I can see she's trembling,\" she said.\n",
      "\n",
      "\"Yeah, but I'm sorry I told her to stop,\" she said. \"For what?\"\n",
      "\n",
      "\"Not now, I just want to comfort her,\" the woman said.\n",
      "\n",
      "With the waitress's assistance, she put the scissors back in place.\n",
      "\n",
      "\n",
      "=== Output 3 ===\n",
      "\"I'm in love with you,\" she said.\n",
      "\n",
      "Citing her personal experience, the mother-of-two told the Guardian she has had \"very, very bad health problems and has had to take a prescription every six months or so for my baby every single day for over a decade.\"\n",
      "\n",
      "\"I'm a full-time mum and I don't have the money to afford my own health care. I'm not an average mum, but I have a huge family,\" she said.\n",
      "\n",
      "\"I've had to take my own life twice, once for an abortion and once for a brain freeze to keep the baby alive.\n",
      "\n",
      "\"[It is] just so sad. My husband and I have had so many family members, he has to go on with his life to keep his life. I don't know if I'll be able to pay for them all.\n",
      "\n",
      "\"To have to go through all this and to have to pay for it all is a real shock. I feel very sad.\n",
      "\n",
      "\"It doesn't just cause pain - it just makes us sick. I don't know if I've ever met someone like that before.\"\n",
      "\n",
      "She added: \"It's not a good thing to have my baby every single day, to have a baby with no money, to\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = \"\\\"I'm in love with you,\\\" she said.\"\n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=200, temperature=0.9, num_return_sequences=3,\n",
    "    do_sample=True)\n",
    "\n",
    "\n",
    "# Print all outputs\n",
    "for i, output in enumerate(result):\n",
    "    print(f\"\\n=== Output {i+1} ===\")\n",
    "    print(output['generated_text'])\n",
    "# print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0d32",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have experimented with text generation, write a brief report on your observations.\n",
    "\n",
    "1. What patterns did you notice in the generated text?\n",
    "2. How did changing the temperature affect the creativity and coherence of the text?\n",
    "3. What types of prompts yielded the most coherent results?\n",
    "4. What are the limitations of GPT-2 based on your experimentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdfe19",
   "metadata": {},
   "source": [
    "In attached pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
